{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    question: str = Field(description=\"The math question to answer.\")\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name = \"Search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        args_schema=CalculatorInput\n",
    "        # coroutine= ... <- you can specify an async method if desired as well\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are acted as a task breakdown expert. Your job is to breakdown a task into a list of subtasks that potentially can be solved by existing tools.\n",
      "Subtasks form a dependency flow graph that solve the main task, so that one subtask may depends on the output of other subtasks.\n",
      "\n",
      "[TOOL_DESCRIPTION]\n",
      "You have access to a set of tools with their description:\n",
      "\n",
      "- Search: useful for when you need to answer questions about current events\n",
      "\n",
      "- Calculator: useful for when you need to answer questions about math\n",
      "\n",
      "\n",
      "[TASK_DESCRIPTION]\n",
      "The task you are working on is:\n",
      "What is the capital of the input country?\n",
      "\n",
      "[INPUT_CONTEXT]\n",
      "Here is the input context given to you (necessary for solving the main task):\n",
      "{\n",
      "  \"country\": string, (The country to find the capital of)\n",
      "}\n",
      "\n",
      "[OUTPUT_SCHEMA]\n",
      "Here is the output schema of the task:\n",
      "{\n",
      "  \"capital\": string, (The capital of the input country)\n",
      "}\n",
      "\n",
      "[PREVIOUS_ATTEMPTS]\n",
      "Here are the previous attempts of breaking down the task and the critiques of each attempt:\n",
      "\n",
      "\n",
      "Based on existing tools, task description, input context, and output schema, you should to the following steps:\n",
      "1. Think about whether the main task can be solved by existing tools.\n",
      "2. If main task is solvable, breakdown the main task into a list of subtasks in natural language.\n",
      "3. Evaluate the subtask list, reflect on how to improve the current subtask list if possible.\n",
      "\n",
      "You should respond in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"solvability_thought\": string, (The thought process you used to determine if the task is solvable)\n",
      "  \"solvable\": boolean, (Whether the task is solvable)\n",
      "  \"subtasks\": string[], (The subtasks you identified; [] if task is not solvable)\n",
      "  \"reflection\": string, (Your reflection on the subtasks breakdown above, any advice to improve; if task is not solvable, or no improvement suggustion)\n",
      "}\n",
      "```\n",
      "\n",
      "Do not wrap ```json ``` around the json output, you should only output the json object itself. Ensure the response can be parsed by Python `json.loads`.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'solvability_thought': 'The main task requires finding the capital of a given country. The Search tool can be used to find information about current events, which includes finding the capital of a country.',\n",
       " 'solvable': True,\n",
       " 'subtasks': ['Use the Search tool to find the capital of the input country'],\n",
       " 'reflection': 'The task can be solved using the Search tool, and the subtask list is straightforward. No improvements are needed.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.experimental.autoflow.schema import Schema, FlowSchemaOutputParser\n",
    "from langchain import PromptTemplate\n",
    "from langchain.experimental.autoflow.prompts import TASK_BREAKDOWN\n",
    "\n",
    "schema = Schema.object(\n",
    "    solvability_thought=Schema.string(\"The thought process you used to determine if the task is solvable\"),\n",
    "    solvable=Schema.boolean(\"Whether the task is solvable\"),\n",
    "    subtasks=Schema.array(Schema.string(), \"The subtasks you identified; [] if task is not solvable\"),\n",
    "    reflection=Schema.string(\"Your reflection on the subtasks breakdown above, any advice to improve; if task is not solvable, or no improvement suggustion\")\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "output_parser = FlowSchemaOutputParser(flow_schema=schema)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    TASK_BREAKDOWN,\n",
    "    template_format=\"jinja2\",\n",
    "    output_parser=output_parser\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True\n",
    ")\n",
    "result = llm_chain.predict_and_parse(\n",
    "    task=\"What is the capital of the input country?\",\n",
    "    input_schema=Schema.object(\n",
    "        country=Schema.string(\"The country to find the capital of\")\n",
    "    ),\n",
    "    output_schema=Schema.object(\n",
    "        capital=Schema.string(\"The capital of the input country\")\n",
    "    ),\n",
    "    attempt_history=[],\n",
    "    format_instructions=output_parser.get_format_instructions(),\n",
    "    tools=tools\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
